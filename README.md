# mini-keras
Build my own neural network library


## Features

### Model
- Sequential

### Layers
- Dense Layer

### Optimizers
- gradient_descent
- gradient_descent_with_momentum
- adam


### Activations
- Sigmoid
- RELU
- Linear

### Loss
- binary_crossentropy

### Regularizer
- l2
- dropouts



